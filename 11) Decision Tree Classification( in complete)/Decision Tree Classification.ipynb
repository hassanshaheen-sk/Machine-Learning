{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Load Data 'titanic_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "data = None\n",
    "df = None\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Do One Hot encoding for categorical varaibles and store in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "df_OneHot = None\n",
    "df_OneHot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here to copy into df\n",
    "df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Create dependent and independent varaibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "X = None\n",
    "Y = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Split the data into training and testing set and set the random state to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here\n",
    "\n",
    "print(xtrain.shape, ytrain.shape)\n",
    "print(xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt = DecisionTreeClassifier(\n",
    "    max_depth=3, criterion='gini', random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred = clf_dt.predict(xtest)\n",
    "dt_pred_prb = clf_dt.predict_proba(xtest)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Find accuracy for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "accuracy_dt = None\n",
    "print(\"Accuracy: {}\".format(accuracy_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Find precision for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "precision_dt = None\n",
    "print(\"Precision: {}\".format(precision_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Find Recall for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "recall_dt = None\n",
    "print(\"Recall: {}\".format(recall_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Find F1 Score for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "dt_f1 = None\n",
    "print(\"F1 Score: {}\".format(dt_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Print Classification Report for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve<br>\n",
    "Importing function to plot ROC AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_roc_curve import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('poster')\n",
    "auc_dt = roc_auc_score(ytest, dt_pred_prb)\n",
    "fpr, tpr, threshold = roc_curve(ytest, dt_pred_prb)\n",
    "plot_roc_curve(fpr, tpr, label='AUC = %0.3f' % auc_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Graphviz 2.38 from this [link](https://graphviz.gitlab.io/_pages/Download/Download_windows.html) and install. Then run below line as per your intallation path. (This step is one time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"Path\"] += os.pathsep + 'C:\\Program Files (x86)\\Graphviz2.38\\bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(clf_dt, out_file=dot_data, filled=True, rounded=True, special_characters=True, feature_names=list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting PNG file of Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.write_png('Decision Tree_Titanic.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tuple = list(zip(X.columns, clf_dt.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(features_tuple, columns=[\n",
    "                           \"Feature Names\", \"Importance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = feature_imp.sort_values(\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Feature Names\", y=\"Importance\", data=feature_imp, color='b')\n",
    "plt.xlabel(\"Titanic Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Decision Classifier - Features Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the following parameters of DecisionTreesClassifier:<br>\n",
    "1. max_depth\n",
    "2. min_sample_split\n",
    "3. min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = []\n",
    "acc_test = []\n",
    "acc_cv = []\n",
    "for i in range(3, 9):\n",
    "    dt = DecisionTreeClassifier(max_depth=i)\n",
    "\n",
    "    # For training set\n",
    "    dt.fit(xtrain, ytrain)\n",
    "    y_tr_predicted_train = dt.predict(xtrain)\n",
    "    \n",
    "    # For testing set\n",
    "    y_tr_predicted_test = dt.predict(xtest)\n",
    "    \n",
    "    # CV scores\n",
    "    acc_cv_scores = cross_val_score(\n",
    "        dt, xtrain, ytrain, cv=5, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "    acc_train.append(accuracy_score(ytrain, y_tr_predicted_train))\n",
    "    acc_test.append(accuracy_score(ytest, y_tr_predicted_test))\n",
    "    acc_cv.append(acc_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "range_ = range(3, 9)\n",
    "sns.lineplot(x=list(range_), y=acc_train, label='Training')\n",
    "sns.lineplot(x=list(range_), y=acc_test, label='Testing')\n",
    "sns.lineplot(x=list(range_), y=acc_cv, label='Cross Validation')\n",
    "plt.ylim(0.6, 0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = []\n",
    "acc_test = []\n",
    "acc_cv = []\n",
    "for i in range(3, 9):\n",
    "    dt = DecisionTreeClassifier(min_samples_split=i)\n",
    "\n",
    "    # For training set\n",
    "    dt.fit(xtrain, ytrain)\n",
    "    y_tr_predicted_train = dt.predict(xtrain)\n",
    "    \n",
    "    # For testing set\n",
    "    y_tr_predicted_test = dt.predict(xtest)\n",
    "    \n",
    "    # CV scores\n",
    "    acc_cv_scores = cross_val_score(\n",
    "        dt, xtrain, ytrain, cv=5, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "    acc_train.append(accuracy_score(ytrain, y_tr_predicted_train))\n",
    "    acc_test.append(accuracy_score(ytest, y_tr_predicted_test))\n",
    "    acc_cv.append(acc_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "range_ = range(3, 9)\n",
    "sns.lineplot(x=list(range_), y=acc_train, label='Training')\n",
    "sns.lineplot(x=list(range_), y=acc_test, label='Testing')\n",
    "sns.lineplot(x=list(range_), y=acc_cv, label='Cross Validation')\n",
    "plt.ylim(0.6, 0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = []\n",
    "acc_test = []\n",
    "acc_cv = []\n",
    "for i in range(3, 9):\n",
    "    dt = DecisionTreeClassifier(min_samples_leaf=i)\n",
    "\n",
    "    # For training set\n",
    "    dt.fit(xtrain, ytrain)\n",
    "    y_tr_predicted_train = dt.predict(xtrain)\n",
    "    \n",
    "    # For testing set\n",
    "    y_tr_predicted_test = dt.predict(xtest)\n",
    "    \n",
    "    # CV scores\n",
    "    acc_cv_scores = cross_val_score(\n",
    "        dt, xtrain, ytrain, cv=5, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "    acc_train.append(accuracy_score(ytrain, y_tr_predicted_train))\n",
    "    acc_test.append(accuracy_score(ytest, y_tr_predicted_test))\n",
    "    acc_cv.append(acc_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "range_ = range(3, 9)\n",
    "sns.lineplot(x=list(range_), y=acc_train, label='Training')\n",
    "sns.lineplot(x=list(range_), y=acc_test, label='Testing')\n",
    "sns.lineplot(x=list(range_), y=acc_cv, label='Cross Validation')\n",
    "plt.ylim(0.6, 0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
